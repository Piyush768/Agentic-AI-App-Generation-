{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d508dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ FAISS index and metadata saved!\n",
      "- Index: /tmp/sikka_api_index.faiss\n",
      "- Metadata: /tmp/sikka_api_metadata.pkl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import faiss\n",
    "import pickle\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load the Sikka API CSV file\n",
    "csv_path = \"/Users/piyushpatil/Desktop/Piyush/Projects/AI Agent /Updated_APIs.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Initialize SentenceTransformer model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Generate embeddings from API descriptions\n",
    "descriptions = df[\"Description\"].astype(str).tolist()\n",
    "embeddings = model.encode(descriptions).astype(\"float32\")\n",
    "\n",
    "# Create FAISS index and add embeddings\n",
    "index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "index.add(embeddings)\n",
    "\n",
    "# Define writable output paths\n",
    "faiss_index_path = \"/tmp/api_index.faiss\"\n",
    "metadata_path = \"/tmp/api_metadata.pkl\"\n",
    "\n",
    "# Save FAISS index\n",
    "faiss.write_index(index, faiss_index_path)\n",
    "\n",
    "# Save API metadata\n",
    "metadata = df.to_dict(orient=\"records\")\n",
    "with open(metadata_path, \"wb\") as f:\n",
    "    pickle.dump(metadata, f)\n",
    "\n",
    "print(f\"✅ FAISS index and metadata saved!\\n- Index: {faiss_index_path}\\n- Metadata: {metadata_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7564ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import pickle\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load embedding model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Load FAISS index\n",
    "index = faiss.read_index(\"/tmp/api_index.faiss\")\n",
    "\n",
    "# Load metadata (API name, description, parameters)\n",
    "with open(\"/tmp/sikka_api_metadata.pkl\", \"rb\") as f:\n",
    "    metadata = pickle.load(f)\n",
    "\n",
    "def search_sikka_api(query: str, k: int = 5) -> list:\n",
    "    \"\"\"Search top matching APIs using semantic FAISS index.\"\"\"\n",
    "    query_embedding = model.encode([query]).astype(\"float32\")\n",
    "    D, I = index.search(query_embedding, k)\n",
    "    query_tokens = query.lower().split()\n",
    "\n",
    "    results = []\n",
    "    for idx, score in zip(I[0], D[0]):\n",
    "        entry = metadata[idx]\n",
    "        param_list = [p.strip() for p in str(entry.get(\"Parameters\", \"\")).split(\",\") if p.strip()]\n",
    "        matched = [p for p in param_list if any(token in p.lower() for token in query_tokens)]\n",
    "\n",
    "        results.append({\n",
    "            \"api_name\": entry.get(\"API Name\", \"N/A\"),\n",
    "            \"description\": entry.get(\"Description\", \"No description\"),\n",
    "            \"endpoint\": entry.get(\"API Endpoints\", \"N/A\"),\n",
    "            \"similarity_score\": float(score),\n",
    "            \"parameters\": param_list,\n",
    "            \"matched_parameters\": matched or [\"No direct match\"]\n",
    "        })\n",
    "    return results\n",
    "\n",
    "def format_api_results(api_list: list) -> str:\n",
    "    \"\"\"Format API results into a readable string for CrewAI agents, with endpoint at top.\"\"\"\n",
    "    output = \"\"\n",
    "    for i, api in enumerate(api_list, 1):\n",
    "        output += f\"\"\"\n",
    "🔹 API #{i}\n",
    "🔗 Endpoint: {api['endpoint']}  <-- Moved this to top!\n",
    "📛 Name: {api['api_name']}\n",
    "📄 Description: {api['description']}\n",
    "📦 Parameters: {', '.join(api['parameters'])}\n",
    "🎯 Matched Parameters: {', '.join(api['matched_parameters'])}\n",
    "------------------------------------------------------------\\n\"\"\"\n",
    "    return output.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b8995f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /opt/anaconda3/lib/python3.11/site-packages (1.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install python-dotenv\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54b96e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ API key loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # ✅ Load variables from .env\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")   # Load the OpenAI API key from .env file\n",
    "# Check if the API key is loaded                    \n",
    "\n",
    "if not api_key:\n",
    "    raise ValueError(\"❌ OPENAI_API_KEY not found in .env file.\")\n",
    "else:\n",
    "    print(\"✅ API key loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90539cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep the same imports you had\n",
    "import os\n",
    "import re\n",
    "from crewai import Agent, Task, Crew\n",
    "from langchain_openai import ChatOpenAI\n",
    "%pip install faiss-cpu\n",
    "# from faiss_search import search_sikka_api, format_api_results\n",
    " \n",
    "# Improved extract_code function\n",
    "def extract_code(output: str, keyword: str) -> str:\n",
    "    language_aliases = {\n",
    "        \"FastAPI\": [\"python\", \"fastapi\", \"py\"],\n",
    "        \"React\": [\"jsx\", \"react\", \"javascript\", \"tsx\", \"js\", \"ts\"],\n",
    "        \"SQL\": [\"sql\", \"postgresql\", \"mysql\"],\n",
    "        \"Shell\": [\"bash\", \"shell\", \"sh\", \"zsh\"]\n",
    "    }\n",
    " \n",
    "    aliases = language_aliases.get(keyword, [keyword])\n",
    "    pattern = \"|\".join([re.escape(alias.lower()) for alias in aliases])\n",
    "    regex = rf\"```(?:{pattern})?\\s*(.*?)```\"\n",
    " \n",
    "    code_blocks = re.findall(regex, str(output), re.DOTALL)\n",
    "    return \"\\n\\n\".join(code_blocks).strip()\n",
    " \n",
    "# Keep your existing run_crew_pipeline function, but with improvements\n",
    "def run_crew_pipeline(query: str, formatted_result: str) -> dict:\n",
    "    \"\"\"Run the CrewAI pipeline to generate code based on the query and API results.\"\"\"\n",
    "    \n",
    "    # Initialize the LLM\n",
    "    try:\n",
    "        llm = ChatOpenAI(model=\"gpt-4-turbo\", temperature=0)\n",
    "    except Exception as e:\n",
    "        print(f\"Error initializing LLM: {str(e)}\")\n",
    "        return {\"error\": f\"LLM initialization failed: {str(e)}\"}\n",
    "    \n",
    "    # 🔹 Improved Agents\n",
    "    planner = Agent(\n",
    "        role=\"System Architect\",\n",
    "        goal=\"Design a complete architecture using appropriate Sikka APIs\",\n",
    "        backstory=\"You're a senior architect with expertise in API integration and system design.\",\n",
    "        llm=llm,\n",
    "    )\n",
    " \n",
    "    backend_dev = Agent(\n",
    "        role=\"Backend Developer\",\n",
    "        goal=\"Write production-quality FastAPI backend code using selected Sikka APIs\",\n",
    "        backstory=\"Expert in Python, REST APIs, and backend integration with proper error handling.\",\n",
    "        llm=llm,\n",
    "    )\n",
    " \n",
    "    frontend_dev = Agent(\n",
    "        role=\"Frontend Developer\",\n",
    "        goal=\"Create a polished React frontend that interacts seamlessly with the backend\",\n",
    "        backstory=\"Frontend expert focused on React, state management, and clean UI design.\",\n",
    "        llm=llm,\n",
    "    )\n",
    " \n",
    "    # 🔹 Improved Tasks\n",
    "    planner_task = Task(\n",
    "        description=f\"\"\"\n",
    "The user prompt is: \\\"{query}\\\"\n",
    " \n",
    "Here are the top relevant Sikka APIs:\n",
    " \n",
    "{formatted_result}\n",
    " \n",
    "Your job:\n",
    "1. Analyze the requirements carefully\n",
    "2. Choose the most appropriate Sikka APIs to use\n",
    "3. Design a comprehensive solution architecture\n",
    "4. Write detailed guidance for the Backend and Frontend Developers\n",
    "\"\"\",\n",
    "        expected_output=\"A detailed architecture plan with specific API selections and implementation guidance.\",\n",
    "        agent=planner,\n",
    "    )\n",
    " \n",
    "    backend_task = Task(\n",
    "        description=\"\"\"\n",
    "Using the planner's architecture:\n",
    "1. Implement complete FastAPI routes for the selected Sikka APIs\n",
    "2. Include proper request/response models\n",
    "3. Add comprehensive error handling\n",
    "4. Ensure security best practices are followed\n",
    "5. Document all endpoints\n",
    " \n",
    "Provide complete, production-ready code with all necessary imports and setup.\n",
    "\"\"\",\n",
    "        expected_output=\"Complete FastAPI backend code wrapped in a code block labeled ```FastAPI```.\",\n",
    "        agent=backend_dev,\n",
    "    )\n",
    " \n",
    "    frontend_task = Task(\n",
    "        description=\"\"\"\n",
    "Using the planner's architecture:\n",
    "1. Create a complete React component that interfaces with the backend\n",
    "2. Implement proper form handling and validation\n",
    "3. Add loading states and error handling\n",
    "4. Design a clean and intuitive user interface\n",
    "5. Ensure all API interactions are properly implemented\n",
    " \n",
    "Provide a complete React implementation, not just snippets.\n",
    "\"\"\",\n",
    "        expected_output=\"Complete React component with clean UI and API integration.\",\n",
    "        agent=frontend_dev,\n",
    "    )\n",
    " \n",
    "    # 🔹 Run the crew with better error handling\n",
    "    try:\n",
    "        crew = Crew(\n",
    "            agents=[planner, backend_dev, frontend_dev],\n",
    "            tasks=[planner_task, backend_task, frontend_task],\n",
    "            verbose=True,\n",
    "        )\n",
    " \n",
    "        final_output = crew.kickoff()\n",
    " \n",
    "        # Extract code with improved function\n",
    "        backend_code = extract_code(str(final_output), \"FastAPI\")\n",
    "        frontend_code = extract_code(str(final_output), \"React\")\n",
    " \n",
    "        return {\n",
    "            \"raw_output\": str(final_output),\n",
    "            \"backend_code\": backend_code if backend_code.strip() else None,\n",
    "            \"frontend_code\": frontend_code if frontend_code.strip() else None\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error in crew execution: {str(e)}\")\n",
    "        return {\n",
    "            \"error\": str(e),\n",
    "            \"raw_output\": None,\n",
    "            \"backend_code\": None,\n",
    "            \"frontend_code\": None\n",
    "        }\n",
    " \n",
    "# For manual testing\n",
    "if __name__ == \"__main__\":\n",
    "    query = \"Make a payment method for a patient\"\n",
    "    api_matches = search_sikka_api(query, k=5)\n",
    "    formatted = format_api_results(api_matches)\n",
    "    result = run_crew_pipeline(query, formatted)\n",
    " \n",
    "    if \"error\" in result and result[\"error\"]:\n",
    "        print(f\"\\n❌ Error: {result['error']}\")\n",
    "    else:\n",
    "        if result[\"backend_code\"]:\n",
    "            print(\"\\n✅ Backend Code Preview:\\n\", result[\"backend_code\"][:200] + \"...\" if len(result[\"backend_code\"]) > 200 else result[\"backend_code\"])\n",
    "        if result[\"frontend_code\"]:\n",
    "            print(\"\\n✅ Frontend Code Preview:\\n\", result[\"frontend_code\"][:200] + \"...\" if len(result[\"frontend_code\"]) > 200 else result[\"frontend_code\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
